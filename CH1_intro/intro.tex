Our knowledge of the world and its ways underlies our unmatched inferential capacity.
It is only by the hard-won acquisition of patterns of truths and behaviors in academic culture, for example, that I can infer that you are probably reading this document prior to its publication, in the role of a reviewer; very few theses, after all, are said to be read after their completion.
This kind of situational inference is the product of an analogical reasoning process by which we compare a situation at hand---here, writing a dissertation---to a model of similar situations; assess properties of the latter that are consistent with, but unobserved in, the former; and tentatively assume the truth of those properties.
While simple ``if-then'' inference rules are often useful---e.g. \textit{if I see smoke, then there is probably a fire}---most situations in reality are complex and multi-faceted. Additional inferences may spring from an observation of smoke: perhaps a firefighter will arrive, and perhaps they will then put the inferred fire out. The predicted arrival and firefighting events, too, may erupt into other, perhaps more mundane, inferences---about the spatiotemporal trajectories of the entities involved, for example, or the relative sizes of people and firetrucks---which inferences are, regardless of their mundanity, frequently important in human-level reasoning. Furthermore, the entities mentioned in an inference, e.g. the fire, must share its identity with the fire entity mentioned in a co-occurring inference. To grant computers human-like knowledge, we need a knowledge \textit{representation} capable of encapsulating these rich, abstract, re-usable networks of co-occurring facts and co-referring entities.

Long before the first flickers of electricity animated any digital computer, though, psychologists were already at work investigating this kind of patterned situational knowledge, often called knowledge \textit{schemas}.
In his 1932 book \textit{Remembering} \citep{bartlett1995remembering}, Frederic Bartlett found that, when people forgot details of stories they were told, they were likely to re-cast events like ``paddling in a canoe'' in terms of more familiar types of event from their own cultures, such as ``sailing in a boat''. \citet{piaget1952origins} defined schemas as \textit{``cohesive, repeatable action sequence[s] possessing component actions that are tightly interconnected and governed by a core meaning''}, and suggested that understanding new information involved either \textit{assimilating} that information into an existing schema, or \textit{accommodating} the information by changing an existing schema to fit it. They also suggested that children start with a small initial set of schemas to ``seed'' the lifelong schema generation process.

The artificial intelligence community has, nearly since its inception, made use of schema-like knowledge representations in various forms; even as this dissertation is written, DARPA is overseeing the Knowledge-directed Artificial Intelligence Reasoning Over Schemas (KAIROS) initiative, which is geared toward the acquisition and application of schemas, especially those covering military and governmental knowledge domains. However, much AI research on schema modeling and acquisition has followed the broader community trend of eschewing complex, symbolic representations for ones more easily learned by statistical, corpus-based methods. While these methods have rapidly accelerated some dimensions of progress, such as the rate of knowledge acquisition, some other dimensions still suffer, such as the representational richness and human interpretability of the acquired knowledge.

Since the invention of the transformer model in 2017, the necessity of knowledge acquisition and representation as an independent step in the march toward artificial general intelligence has increasingly been called into question. A growing number of tasks are being approached in an ``end-to-end'' manner, with a large, pre-trained language (or multi-modal) model accepting a task description and producing a response without reference to an external, interpretable knowledge base. The nature of the knowledge acquired by pre-trained transformer models is not currently well understood, however, and as we paw at their internal weights in search of that nature, systems based on these models remain liable to make embarrassing, or even dangerous, mistakes.

This dissertation aims to enter the discourse with a new model of schemas and a new way to learn them. The schemas introduced here are written in a rich formal representation, \textit{Episodic Logic} (EL), which nevertheless mirrors English structure closely enough that knowledge written in it can be re-written and presented to humans untrained in EL interpretation. These EL schemas model a set of typed entities, represented as variables; temporally related events involving those entities; and the goals, preconditions, and postconditions teleologically underlying the schema as a whole. The modeling of entities as variables allows the schemas to be fit to natural language sentences, first parsed to EL, and to generate inferences about unstated truths from those sentences. For example, if ``Jill the firefighter drives to a house'' were matched to a firefighting schema, binding ``Jill'' to its generalized firefighter variable, the schema could then produce the inference that Jill later puts out a fire. The EL schema model also supports hierarchical nesting of schemas as steps of other schemas, and can be further organized into a taxonomic hierarchy of progressively more specialized versions of schemas.

I also show that, despite the representational richness of EL schemas, their automatic acquisition is feasible. Beginning with a small set of initial \textit{protoschemas}, meant to cover a wide range of situations at a very general level, we describe a schema learning process by which progressively more complex schemas are learned on the basis of simpler ones. I introduce a system for matching these simple protoschemas to text using state-of-the-art neural semantic parsers combined with the rich EL schema representation. I then introduce \textit{latent schema sampling}, a process based around a story generator built from a large, pre-trained language model. The use of the language model in latent schema sampling can be viewed through two lenses: through one, it is a means of continuously generating a story corpus rather than relying on a limited dataset; through the other, it is a demonstration that symbolic schema knowledge can be \textit{extracted from} large language models and represented in an interpretable, mechanistically useful way.

%To continue my earlier example: I have never written a dissertation, and am aware of no explicit axiom prohibiting the kind of informal, discursive, example-oriented style of introduction I prefer to employ.
%But I \textit{do} have experience with publishing other academic works, and in my model of \textit{that} kind of situation, I am not infrequently asked to ``button up'' any prose not in line with the (similarly hard-won) norms of academic writing; this situational analogy lets me infer, with some probability or another, a similar outcome in this situation.
%Regardless of the introductory essay at its head, though, this dissertation concerns itself with the formal modeling, unsupervised acquisition from stories, and predictive capacity of these situational models, henceforth \textit{schemas}.